{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13fd7a6c",
   "metadata": {},
   "source": [
    "# WSB Dataset Exploration\n",
    "\n",
    "This notebook file shows an exemplary dataset analysis created for the paper submission.\n",
    "The code can easily be modified to investigate further properties of the dataset, if required.\n",
    "\n",
    "\n",
    "# 1. Load datasets and create filtered subset\n",
    "\n",
    "## 1.1. WallStreetBets submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3219230",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8607dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load WSB submission dataset\n",
    "with open('datasets/submissions_WSB_20220703.json') as f:\n",
    "    submission_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0e8b723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Created filtered subset of submissions by removing deleted and reactive posts:\n",
    "def check_selftext(txt):\n",
    "    return (txt in [\"[deleted]\", \"[removed]\", \"\"])\n",
    "\n",
    "def check_flair(flair):\n",
    "    return (flair in [\"Meme\", \"Gain\", \"Loss\", \"Shitpost\", \"Satire\", \"Donation\", \"Question\"])\n",
    "\n",
    "submission_data_filtered = []\n",
    "for s in submission_data:\n",
    "    # Only consider posts that have a selftext\n",
    "    if 'selftext' in s:\n",
    "        # Only consider posts that are not deleted or removed\n",
    "        if check_selftext(s['selftext']):\n",
    "            pass\n",
    "        else:\n",
    "            # Only consider posts that have a flair with predictive nature\n",
    "            if 'link_flair_text' in s:\n",
    "                if check_flair(s['link_flair_text']):\n",
    "                    pass\n",
    "                else:\n",
    "                    submission_data_filtered.append(s)\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7eec6ff",
   "metadata": {},
   "source": [
    "## 1.2. Combined WSB signal & stock price dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee8b637c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('datasets/stock_dfs_2022-07-03.json', 'r') as f:\n",
    "    stock_dfs = json.load(f)\n",
    "    \n",
    "ticker_list = []\n",
    "\n",
    "for i, s in enumerate(stock_dfs):\n",
    "    stock_dfs[i] = pd.DataFrame.from_dict(s)\n",
    "    stock_dfs[i].index = pd.to_datetime(stock_dfs[i].index, format='%Y-%m-%d')\n",
    "    \n",
    "    # Save list of tickers for further use\n",
    "    ticker_list.append(stock_dfs[i].columns[0])\n",
    "    \n",
    "    # Rename ticker_specific columns:\n",
    "    stock_dfs[i] = stock_dfs[i].rename(columns={stock_dfs[i].columns[0]: 'count', \n",
    "                                                stock_dfs[i].columns[8]: 'count_window'})\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "757c05b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('datasets/stock_dfs_filtered_2022-07-03.json', 'r') as f:\n",
    "    stock_dfs_filtered = json.load(f)\n",
    "    \n",
    "ticker_list_filtered = []\n",
    "\n",
    "for i, s in enumerate(stock_dfs_filtered):\n",
    "    stock_dfs_filtered[i] = pd.DataFrame.from_dict(s)\n",
    "    stock_dfs_filtered[i].index = pd.to_datetime(stock_dfs_filtered[i].index, format='%Y-%m-%d')\n",
    "    \n",
    "    # Save list of tickers for further use\n",
    "    ticker_list_filtered.append(stock_dfs_filtered[i].columns[0])\n",
    "    \n",
    "    # Rename ticker_specific columns:\n",
    "    stock_dfs_filtered[i] = stock_dfs_filtered[i].rename(columns={stock_dfs_filtered[i].columns[0]: 'count', \n",
    "                                                                  stock_dfs_filtered[i].columns[8]: 'count_window'})\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2dd315",
   "metadata": {},
   "source": [
    "## 1.3. Preprocessed / feature engineered dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "142d4b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "submission_df = pd.read_pickle('datasets/submission_df_2022-07-03.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6cb743c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['all_awardings', 'allow_live_comments', 'author', 'author_flair_background_color', 'author_flair_css_class', 'author_flair_richtext', 'author_flair_text', 'author_flair_text_color', 'author_flair_type', 'author_fullname', 'author_is_blocked', 'author_patreon_flair', 'author_premium', 'awarders', 'can_mod_post', 'contest_mode', 'created_utc', 'domain', 'full_link', 'gildings', 'id', 'is_created_from_ads_ui', 'is_crosspostable', 'is_meta', 'is_original_content', 'is_reddit_media_domain', 'is_robot_indexable', 'is_self', 'is_video', 'link_flair_background_color', 'link_flair_css_class', 'link_flair_richtext', 'link_flair_template_id', 'link_flair_text', 'link_flair_text_color', 'link_flair_type', 'locked', 'media_only', 'no_follow', 'num_comments', 'num_crossposts', 'over_18', 'parent_whitelist_status', 'permalink', 'pinned', 'post_hint', 'preview', 'pwls', 'retrieved_on', 'score', 'selftext', 'send_replies', 'spoiler', 'stickied', 'subreddit', 'subreddit_id', 'subreddit_subscribers', 'subreddit_type', 'suggested_sort', 'thumbnail', 'title', 'total_awards_received', 'treatment_tags', 'upvote_ratio', 'url', 'whitelist_status', 'wls', 'date', 'text_lengths', 'polarity', 'subjectivity', 'tickers', 'top_ticker', 'BUY_post', 'spacy_vector', 'media_metadata', 'thumbnail_height', 'thumbnail_width', 'count', '$count', 'BUY', 'HOLD', 'SELL', 'BUY_ngrams', 'posts', 'count_window', 'BUY_signal', 'SELL_signal', 'activity', 'Open', 'High', 'Low', 'Close', 'Volatility', 'Volume', 'Dividends', 'Stock Splits', 'close_diff', 'any_buy', 'Morgan Stanley', 'Credit Suisse', 'Wells Fargo', 'Citigroup', 'Barclays', 'Deutsche Bank', 'UBS', 'Raymond James', 'JP Morgan', 'B of A Securities', 'BMO Capital', 'Keybanc', 'RBC Capital', 'Goldman Sachs', 'Mizuho', 'Stifel', 'Piper Sandler', 'Baird', 'Jefferies', 'Oppenheimer', 'weekday', 'prev_1w', 'prev_3d', 'prev_1d', 'change_1d', 'change_3d', 'change_1w', 'change_1m', 'change_3m', 'MA07', 'MA30', 'MA90', 'BUY_MA30', 'any_buy_MA30', 'author_flair_template_id', 'author_cakeday', 'call_to_action', 'category', 'poll_data', 'edited', 'collections', 'media', 'media_embed', 'secure_media', 'secure_media_embed', 'distinguished', 'gilded', 'removed_by_category', 'discussion_type', 'event_end', 'event_is_live', 'event_start', 'steward_reports', 'updated_utc', 'og_description', 'og_title', 'author_created_utc', 'content_categories', 'removal_reason', 'archived', 'can_gild', 'hidden', 'quarantine', 'subreddit_name_prefixed', 'rte_mode', 'author_id', 'brand_safe', 'previous_visits']\n"
     ]
    }
   ],
   "source": [
    "# Show columns of submission_df\n",
    "print(submission_df.columns.to_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a132b6",
   "metadata": {},
   "source": [
    "# 2. General statistics and information\n",
    "\n",
    "## 2.1. WallStreetBets submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "671f9580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features provided by the Pushshift API: 67 \n",
      "\n",
      "List of all features:\n",
      "dict_keys(['all_awardings', 'allow_live_comments', 'author', 'author_flair_background_color', 'author_flair_css_class', 'author_flair_richtext', 'author_flair_text', 'author_flair_text_color', 'author_flair_type', 'author_fullname', 'author_is_blocked', 'author_patreon_flair', 'author_premium', 'awarders', 'can_mod_post', 'contest_mode', 'created_utc', 'domain', 'full_link', 'gildings', 'id', 'is_created_from_ads_ui', 'is_crosspostable', 'is_meta', 'is_original_content', 'is_reddit_media_domain', 'is_robot_indexable', 'is_self', 'is_video', 'link_flair_background_color', 'link_flair_css_class', 'link_flair_richtext', 'link_flair_template_id', 'link_flair_text', 'link_flair_text_color', 'link_flair_type', 'locked', 'media_only', 'no_follow', 'num_comments', 'num_crossposts', 'over_18', 'parent_whitelist_status', 'permalink', 'pinned', 'post_hint', 'preview', 'pwls', 'retrieved_on', 'score', 'selftext', 'send_replies', 'spoiler', 'stickied', 'subreddit', 'subreddit_id', 'subreddit_subscribers', 'subreddit_type', 'suggested_sort', 'thumbnail', 'title', 'total_awards_received', 'treatment_tags', 'upvote_ratio', 'url', 'whitelist_status', 'wls'])\n"
     ]
    }
   ],
   "source": [
    "# Features included in the dataset\n",
    "print(f'Number of features provided by the Pushshift API: {len(submission_data_filtered[0].keys())} \\n')\n",
    "print('List of all features:')\n",
    "print(submission_data_filtered[0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05d159a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of raw posts in dataset: 1670273\n"
     ]
    }
   ],
   "source": [
    "# Number of posts in dataset\n",
    "print(f'Number of raw posts in dataset: {len(submission_data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a1b0d5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Earliest post from (UTC time):\n",
      "2017-12-31 07:21:44\n",
      "\n",
      "Latest post from (UTC time):\n",
      "2022-07-03 06:27:29\n"
     ]
    }
   ],
   "source": [
    "# Time range of posts\n",
    "t_min = submission_data[-1]['created_utc']\n",
    "t_max = submission_data[0]['created_utc']\n",
    "\n",
    "print('Earliest post from (UTC time):')\n",
    "print(datetime.datetime.fromtimestamp(t_min).strftime('%Y-%m-%d %H:%M:%S'))\n",
    "print('\\nLatest post from (UTC time):')\n",
    "print(datetime.datetime.fromtimestamp(t_max).strftime('%Y-%m-%d %H:%M:%S'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d447bb48",
   "metadata": {},
   "source": [
    "## 2.2. Combined WSB signal & stock price dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a684424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['count', '$count', 'BUY', 'HOLD', 'SELL', 'BUY_ngrams', 'score',\n",
      "       'posts', 'count_window', 'BUY_signal', 'SELL_signal', 'activity',\n",
      "       'Open', 'High', 'Low', 'Close', 'Volatility', 'Volume', 'Dividends',\n",
      "       'Stock Splits', 'close_diff', 'any_buy', 'Morgan Stanley',\n",
      "       'Credit Suisse', 'Wells Fargo', 'Citigroup', 'Barclays',\n",
      "       'Deutsche Bank', 'UBS', 'Raymond James', 'JP Morgan',\n",
      "       'B of A Securities', 'BMO Capital', 'Keybanc', 'RBC Capital',\n",
      "       'Goldman Sachs', 'Mizuho', 'Stifel', 'Piper Sandler', 'Baird',\n",
      "       'Jefferies', 'Oppenheimer', 'weekday', 'prev_1w', 'prev_3d', 'prev_1d',\n",
      "       'change_1d', 'change_3d', 'change_1w', 'change_1m', 'change_3m', 'MA07',\n",
      "       'MA30', 'MA90', 'BUY_MA30', 'any_buy_MA30'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Which columns does the stock market dataset include?\n",
    "print(stock_dfs[0].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb29700e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     count  $count  BUY  HOLD  SELL  BUY_ngrams  posts  BUY_signal  \\\n",
      "0      105      33   43     3    17           3    105          42   \n",
      "1       11       1    5     0     2           0     11           5   \n",
      "2       88      27   29     1    11           2     88          29   \n",
      "3      110      34   43     0    10           3    110          43   \n",
      "4       20       3    9     0     4           0     20           9   \n",
      "..     ...     ...  ...   ...   ...         ...    ...         ...   \n",
      "498     96      30   31     1    11           4     96          31   \n",
      "499     15       3    5     0     3           1     15           5   \n",
      "500     11       2    4     0     2           0     11           4   \n",
      "501     12       1    5     1     2           0     12           5   \n",
      "502     11       1    6     0     1           0     11           6   \n",
      "\n",
      "     SELL_signal  \n",
      "0             16  \n",
      "1              2  \n",
      "2             11  \n",
      "3             10  \n",
      "4              4  \n",
      "..           ...  \n",
      "498           10  \n",
      "499            3  \n",
      "500            2  \n",
      "501            2  \n",
      "502            1  \n",
      "\n",
      "[503 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "# Number of signals extracted from all WSB submissions:\n",
    "signal_counts = []\n",
    "\n",
    "for df in stock_dfs:\n",
    "    signal_counts.append(df[['count', '$count', 'BUY', 'HOLD', 'SELL', \n",
    "                             'BUY_ngrams', 'posts', 'BUY_signal', 'SELL_signal']].astype(bool).sum(axis=0))\n",
    "    \n",
    "signal_counts_df = pd.DataFrame(signal_counts)\n",
    "print(signal_counts_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "19ba473d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count          46178\n",
      "$count         13574\n",
      "BUY            18316\n",
      "HOLD            1422\n",
      "SELL            9152\n",
      "BUY_ngrams      1910\n",
      "posts          46178\n",
      "BUY_signal     16649\n",
      "SELL_signal     6866\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Distribution of the different signal types:\n",
    "print(signal_counts_df.sum(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c8901a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count          28007\n",
       "$count          5785\n",
       "BUY            12315\n",
       "HOLD             841\n",
       "SELL            5928\n",
       "BUY_ngrams       895\n",
       "posts          28007\n",
       "BUY_signal     11522\n",
       "SELL_signal     4902\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of signals extracted from filtered WSB submissions:\n",
    "signal_counts_filtered = []\n",
    "\n",
    "for df in stock_dfs_filtered:\n",
    "    signal_counts_filtered.append(df[['count', '$count', 'BUY', 'HOLD', 'SELL', \n",
    "                                  'BUY_ngrams', 'posts', 'BUY_signal', 'SELL_signal']].astype(bool).sum(axis=0))\n",
    "    \n",
    "signal_counts_filtered_df = pd.DataFrame(signal_counts_filtered)\n",
    "signal_counts_filtered_df.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "765ae409",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>$count</th>\n",
       "      <th>BUY</th>\n",
       "      <th>HOLD</th>\n",
       "      <th>SELL</th>\n",
       "      <th>BUY_ngrams</th>\n",
       "      <th>posts</th>\n",
       "      <th>BUY_signal</th>\n",
       "      <th>SELL_signal</th>\n",
       "      <th>ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>1001</td>\n",
       "      <td>495</td>\n",
       "      <td>605</td>\n",
       "      <td>80</td>\n",
       "      <td>423</td>\n",
       "      <td>147</td>\n",
       "      <td>1001</td>\n",
       "      <td>457</td>\n",
       "      <td>176</td>\n",
       "      <td>TSLA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>776</td>\n",
       "      <td>222</td>\n",
       "      <td>420</td>\n",
       "      <td>25</td>\n",
       "      <td>217</td>\n",
       "      <td>42</td>\n",
       "      <td>776</td>\n",
       "      <td>359</td>\n",
       "      <td>140</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>850</td>\n",
       "      <td>205</td>\n",
       "      <td>455</td>\n",
       "      <td>36</td>\n",
       "      <td>218</td>\n",
       "      <td>77</td>\n",
       "      <td>850</td>\n",
       "      <td>386</td>\n",
       "      <td>121</td>\n",
       "      <td>AMD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>686</td>\n",
       "      <td>178</td>\n",
       "      <td>333</td>\n",
       "      <td>20</td>\n",
       "      <td>173</td>\n",
       "      <td>28</td>\n",
       "      <td>686</td>\n",
       "      <td>287</td>\n",
       "      <td>117</td>\n",
       "      <td>AMZN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>613</td>\n",
       "      <td>155</td>\n",
       "      <td>332</td>\n",
       "      <td>23</td>\n",
       "      <td>161</td>\n",
       "      <td>28</td>\n",
       "      <td>613</td>\n",
       "      <td>290</td>\n",
       "      <td>103</td>\n",
       "      <td>MSFT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>142</td>\n",
       "      <td>142</td>\n",
       "      <td>38</td>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>142</td>\n",
       "      <td>37</td>\n",
       "      <td>27</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>380</td>\n",
       "      <td>134</td>\n",
       "      <td>176</td>\n",
       "      <td>9</td>\n",
       "      <td>91</td>\n",
       "      <td>11</td>\n",
       "      <td>380</td>\n",
       "      <td>160</td>\n",
       "      <td>77</td>\n",
       "      <td>DIS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>491</td>\n",
       "      <td>109</td>\n",
       "      <td>230</td>\n",
       "      <td>18</td>\n",
       "      <td>94</td>\n",
       "      <td>26</td>\n",
       "      <td>491</td>\n",
       "      <td>210</td>\n",
       "      <td>69</td>\n",
       "      <td>NVDA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>337</td>\n",
       "      <td>99</td>\n",
       "      <td>170</td>\n",
       "      <td>6</td>\n",
       "      <td>48</td>\n",
       "      <td>17</td>\n",
       "      <td>337</td>\n",
       "      <td>162</td>\n",
       "      <td>36</td>\n",
       "      <td>MU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>322</td>\n",
       "      <td>85</td>\n",
       "      <td>137</td>\n",
       "      <td>9</td>\n",
       "      <td>93</td>\n",
       "      <td>7</td>\n",
       "      <td>322</td>\n",
       "      <td>121</td>\n",
       "      <td>80</td>\n",
       "      <td>BA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     count  $count  BUY  HOLD  SELL  BUY_ngrams  posts  BUY_signal  \\\n",
       "443   1001     495  605    80   423         147   1001         457   \n",
       "45     776     222  420    25   217          42    776         359   \n",
       "28     850     205  455    36   218          77    850         386   \n",
       "26     686     178  333    20   173          28    686         287   \n",
       "316    613     155  332    23   161          28    613         290   \n",
       "204    142     142   38     4    28           0    142          37   \n",
       "152    380     134  176     9    91          11    380         160   \n",
       "349    491     109  230    18    94          26    491         210   \n",
       "315    337      99  170     6    48          17    337         162   \n",
       "71     322      85  137     9    93           7    322         121   \n",
       "\n",
       "     SELL_signal ticker  \n",
       "443          176   TSLA  \n",
       "45           140   AAPL  \n",
       "28           121    AMD  \n",
       "26           117   AMZN  \n",
       "316          103   MSFT  \n",
       "204           27      F  \n",
       "152           77    DIS  \n",
       "349           69   NVDA  \n",
       "315           36     MU  \n",
       "71            80     BA  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Most frequently recommended stock tickers:\n",
    "signal_counts_filtered_df['ticker'] = pd.Series(ticker_list)\n",
    "signal_counts_filtered_df.sort_values('$count', ascending=False).head(10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dd0e4c3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TSLA', 'AAPL', 'AMD', 'AMZN', 'MSFT', 'F', 'DIS', 'NVDA', 'MU', 'BA', 'MRNA', 'TWTR', 'NFLX', 'PFE', 'ATVI', 'INTC', 'T', 'WMT', 'GOOG', 'SBUX', 'GE', 'PYPL', 'TGT', 'GM', 'CRM', 'AAL', 'CCL', 'COST', 'BAC', 'XOM', 'V', 'LMT', 'JPM', 'GOOGL', 'MO', 'HD', 'GILD', 'MTCH', 'NKE', 'DAL', 'WBA', 'JNJ', 'LUV', 'KO', 'CSCO', 'BBY', 'NCLH', 'MGM', 'MCD', 'ETSY']\n"
     ]
    }
   ],
   "source": [
    "# Top 50 stock tickers:\n",
    "print(signal_counts_filtered_df.sort_values('$count', ascending=False).head(50)['ticker'].to_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a8909a",
   "metadata": {},
   "source": [
    "# 3. Post categories (flairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ddeab22e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Discussion', 518103),\n",
       " ('Meme', 250251),\n",
       " ('YOLO', 232052),\n",
       " ('News', 131925),\n",
       " ('Gain', 128711),\n",
       " ('DD', 80582),\n",
       " ('Loss', 65877),\n",
       " ('Shitpost', 62817),\n",
       " ('Technical Analysis', 18883),\n",
       " ('Chart', 17380),\n",
       " ('Options', 15406),\n",
       " ('Stocks', 14081),\n",
       " ('Fundamentals', 6423),\n",
       " ('Satire', 4926),\n",
       " ('Storytime', 4822),\n",
       " ('Technicals', 4406),\n",
       " ('Futures', 1792),\n",
       " ('Donation', 1606),\n",
       " ('Daily Discussion', 1497),\n",
       " ('Question', 357)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show distribution of flairs in raw posts\n",
    "from collections import Counter\n",
    "\n",
    "flairs = []\n",
    "for s in submission_data:\n",
    "    if 'link_flair_text' in s:\n",
    "        flairs.append(s['link_flair_text'])\n",
    "        \n",
    "flair_counter = Counter(flairs)\n",
    "flair_counter.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a5f01706",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Discussion', 120758),\n",
       " ('DD', 29513),\n",
       " ('YOLO', 26651),\n",
       " ('News', 12399),\n",
       " ('Options', 5332),\n",
       " ('Technical Analysis', 4571),\n",
       " ('Stocks', 4220),\n",
       " ('Fundamentals', 2235),\n",
       " ('Storytime', 1846),\n",
       " ('Daily Discussion', 1487),\n",
       " ('Technicals', 1394),\n",
       " ('Chart', 642),\n",
       " ('Futures', 496),\n",
       " ('Weekend Discussion', 112),\n",
       " ('Earnings Thread', 66),\n",
       " ('Forex', 65),\n",
       " ('Mods', 56),\n",
       " ('News | PLTR', 38),\n",
       " ('Daily Thread', 31),\n",
       " ('WSBbooks', 24)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show distribution of flairs in raw posts\n",
    "from collections import Counter\n",
    "\n",
    "flairs_filtered = []\n",
    "for s_f in submission_data_filtered:\n",
    "    if 'link_flair_text' in s_f:\n",
    "        flairs_filtered.append(s_f['link_flair_text'])\n",
    "        \n",
    "flair_counter_filtered = Counter(flairs_filtered)\n",
    "flair_counter_filtered.most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591c9e82",
   "metadata": {},
   "source": [
    "# 4. Baseline prediction performances\n",
    "\n",
    "## 4.1. WallStreetBets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "68fd6f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract price changes from submission_df:\n",
    "wsb_performance_df = submission_df[['date', 'change_1d', 'change_3d', \n",
    "                                    'change_1w', 'change_1m', 'change_3m']].dropna().set_index('date') \n",
    "\n",
    "wsb_performance_df.index = pd.to_datetime(wsb_performance_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "27b4946b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "change_1d    0.029012\n",
       "change_3d    0.040775\n",
       "change_1w    0.103033\n",
       "change_1m    1.654077\n",
       "change_3m    5.543383\n",
       "dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mean price change for Q3 2021:\n",
    "t_min_q3 = '2021-07-01'\n",
    "t_max_q3 = '2021-09-30'\n",
    "\n",
    "wsb_performance_df.loc[t_min_q3 : t_max_q3].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ed8c6c72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "change_1d     0.024330\n",
       "change_3d    -0.412591\n",
       "change_1w    -0.765980\n",
       "change_1m    -3.177427\n",
       "change_3m   -12.714791\n",
       "dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mean price change for Q1 2021:\n",
    "t_min_q1 = '2022-01-01'\n",
    "t_max_q1 = '2022-03-31'\n",
    "\n",
    "wsb_performance_df.loc[t_min_q1 : t_max_q1].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56cb414d",
   "metadata": {},
   "source": [
    "## 4.2. S&P 500 index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "20881e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is important to have an up-to-date version of yfinance, as the API is frequently changing\n",
    "# !pip install --update yfinance\n",
    "import yfinance as yf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "017ec5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract S&P 500 stock market data from Yahoo! Finance API\n",
    "sp500_data = yf.Ticker('^GSPC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "abf62ec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-24-227bce1ba179>:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sp500_change['date'] = sp500_change.index.strftime('%Y-%m-%d')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SP500_change_1d</th>\n",
       "      <th>SP500_change_3d</th>\n",
       "      <th>SP500_change_1w</th>\n",
       "      <th>SP500_change_1m</th>\n",
       "      <th>SP500_change_3m</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-02 00:00:00-05:00</th>\n",
       "      <td>0.639882</td>\n",
       "      <td>1.756053</td>\n",
       "      <td>2.661538</td>\n",
       "      <td>0.104600</td>\n",
       "      <td>1.183685</td>\n",
       "      <td>2018-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-03 00:00:00-05:00</th>\n",
       "      <td>0.402864</td>\n",
       "      <td>1.277152</td>\n",
       "      <td>2.697321</td>\n",
       "      <td>0.668614</td>\n",
       "      <td>0.629172</td>\n",
       "      <td>2018-01-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-04 00:00:00-05:00</th>\n",
       "      <td>0.703377</td>\n",
       "      <td>1.002208</td>\n",
       "      <td>1.924748</td>\n",
       "      <td>0.302130</td>\n",
       "      <td>-0.460356</td>\n",
       "      <td>2018-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-05 00:00:00-05:00</th>\n",
       "      <td>0.166234</td>\n",
       "      <td>0.185191</td>\n",
       "      <td>2.165764</td>\n",
       "      <td>-0.980256</td>\n",
       "      <td>-0.754240</td>\n",
       "      <td>2018-01-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-08 00:00:00-05:00</th>\n",
       "      <td>0.130293</td>\n",
       "      <td>0.722423</td>\n",
       "      <td>1.831346</td>\n",
       "      <td>-1.687947</td>\n",
       "      <td>-1.003748</td>\n",
       "      <td>2018-01-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-09 00:00:00-05:00</th>\n",
       "      <td>-0.111223</td>\n",
       "      <td>1.270311</td>\n",
       "      <td>2.144812</td>\n",
       "      <td>-1.720287</td>\n",
       "      <td>-1.392804</td>\n",
       "      <td>2018-01-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-10 00:00:00-05:00</th>\n",
       "      <td>0.703365</td>\n",
       "      <td>1.025749</td>\n",
       "      <td>3.083439</td>\n",
       "      <td>-0.033837</td>\n",
       "      <td>-0.553810</td>\n",
       "      <td>2018-01-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-11 00:00:00-05:00</th>\n",
       "      <td>0.674960</td>\n",
       "      <td>1.264652</td>\n",
       "      <td>2.586026</td>\n",
       "      <td>0.435042</td>\n",
       "      <td>-1.558055</td>\n",
       "      <td>2018-01-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-12 00:00:00-05:00</th>\n",
       "      <td>-0.352449</td>\n",
       "      <td>0.423152</td>\n",
       "      <td>1.841193</td>\n",
       "      <td>-1.505971</td>\n",
       "      <td>-1.900409</td>\n",
       "      <td>2018-01-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-16 00:00:00-05:00</th>\n",
       "      <td>0.941505</td>\n",
       "      <td>1.220281</td>\n",
       "      <td>2.262989</td>\n",
       "      <td>-2.254336</td>\n",
       "      <td>-1.752614</td>\n",
       "      <td>2018-01-16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           SP500_change_1d  SP500_change_3d  SP500_change_1w  \\\n",
       "Date                                                                           \n",
       "2018-01-02 00:00:00-05:00         0.639882         1.756053         2.661538   \n",
       "2018-01-03 00:00:00-05:00         0.402864         1.277152         2.697321   \n",
       "2018-01-04 00:00:00-05:00         0.703377         1.002208         1.924748   \n",
       "2018-01-05 00:00:00-05:00         0.166234         0.185191         2.165764   \n",
       "2018-01-08 00:00:00-05:00         0.130293         0.722423         1.831346   \n",
       "2018-01-09 00:00:00-05:00        -0.111223         1.270311         2.144812   \n",
       "2018-01-10 00:00:00-05:00         0.703365         1.025749         3.083439   \n",
       "2018-01-11 00:00:00-05:00         0.674960         1.264652         2.586026   \n",
       "2018-01-12 00:00:00-05:00        -0.352449         0.423152         1.841193   \n",
       "2018-01-16 00:00:00-05:00         0.941505         1.220281         2.262989   \n",
       "\n",
       "                           SP500_change_1m  SP500_change_3m        date  \n",
       "Date                                                                     \n",
       "2018-01-02 00:00:00-05:00         0.104600         1.183685  2018-01-02  \n",
       "2018-01-03 00:00:00-05:00         0.668614         0.629172  2018-01-03  \n",
       "2018-01-04 00:00:00-05:00         0.302130        -0.460356  2018-01-04  \n",
       "2018-01-05 00:00:00-05:00        -0.980256        -0.754240  2018-01-05  \n",
       "2018-01-08 00:00:00-05:00        -1.687947        -1.003748  2018-01-08  \n",
       "2018-01-09 00:00:00-05:00        -1.720287        -1.392804  2018-01-09  \n",
       "2018-01-10 00:00:00-05:00        -0.033837        -0.553810  2018-01-10  \n",
       "2018-01-11 00:00:00-05:00         0.435042        -1.558055  2018-01-11  \n",
       "2018-01-12 00:00:00-05:00        -1.505971        -1.900409  2018-01-12  \n",
       "2018-01-16 00:00:00-05:00        -2.254336        -1.752614  2018-01-16  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create DataFrame with relevant time frames\n",
    "# Full time frame:\n",
    "t_min = '2018-01-01'\n",
    "t_max = '2022-07-03'\n",
    "\n",
    "idx = pd.date_range(t_min, t_max)\n",
    "\n",
    "# Extract S&P 500 price history\n",
    "sp500_prices = sp500_data.history(start=t_min, end=t_max).fillna(method='ffill') #.reindex(idx)\n",
    "sp500_prices['SP500_change_1d'] = (sp500_prices['Close'].shift(periods=-1)*100/sp500_prices['Close'])-100\n",
    "sp500_prices['SP500_change_3d'] = (sp500_prices['Close'].shift(periods=-3)*100/sp500_prices['Close'])-100\n",
    "sp500_prices['SP500_change_1w'] = (sp500_prices['Close'].shift(periods=-7)*100/sp500_prices['Close'])-100\n",
    "sp500_prices['SP500_change_1m'] = (sp500_prices['Close'].shift(periods=-30)*100/sp500_prices['Close'])-100\n",
    "sp500_prices['SP500_change_3m'] = (sp500_prices['Close'].shift(periods=-90)*100/sp500_prices['Close'])-100\n",
    "sp500_change = sp500_prices[['SP500_change_1d', 'SP500_change_3d', 'SP500_change_1w', \n",
    "                             'SP500_change_1m', 'SP500_change_3m']]\n",
    "\n",
    "sp500_change['date'] = sp500_change.index.strftime('%Y-%m-%d')\n",
    "sp500_change[:10]\n",
    "\n",
    "# sp500_prices[f'SP500_change_{target}'] = (sp500_prices['Close'].shift(periods=-target_in_days)*100/sp500_prices['Close'])-100\n",
    "# sp500_change = sp500_prices[[f'SP500_change_{target}']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4b363dc6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SP500_change_1d    0.015889\n",
       "SP500_change_3d    0.003129\n",
       "SP500_change_1w    0.034506\n",
       "SP500_change_1m    1.496383\n",
       "SP500_change_3m    4.680427\n",
       "dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q3 2021:\n",
    "sp500_change.loc[t_min_q3 : t_max_q3][['SP500_change_1d', 'SP500_change_3d', 'SP500_change_1w', \n",
    "                             'SP500_change_1m', 'SP500_change_3m']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "96757f75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SP500_change_1d    -0.077565\n",
       "SP500_change_3d    -0.190417\n",
       "SP500_change_1w    -0.461547\n",
       "SP500_change_1m    -2.721792\n",
       "SP500_change_3m   -13.021520\n",
       "dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q1 2022:\n",
    "sp500_change.loc[t_min_q1 : t_max_q1][['SP500_change_1d', 'SP500_change_3d', 'SP500_change_1w', \n",
    "                             'SP500_change_1m', 'SP500_change_3m']].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62f8d15",
   "metadata": {},
   "source": [
    "## 4.3. Investment Banks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "752aecf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      change_1d   change_3d   change_1w   change_1m   change_3m\n",
      "0     99.865330   98.564209  100.363817  102.619654  100.025860\n",
      "1    100.000000   98.940405  100.149017  104.569539  103.917907\n",
      "2    100.692939   99.714173   98.796019   97.245565  100.528535\n",
      "3     98.557550  101.017310  100.488924  103.926522  112.221055\n",
      "4    100.000000   99.274685   98.093117   95.107038  108.959052\n",
      "..          ...         ...         ...         ...         ...\n",
      "728  100.678980  101.689561  102.810675  108.587932  102.100341\n",
      "729  101.308771  100.519458   98.293194   98.994804   98.434261\n",
      "730  105.022420  105.022420  102.511213  108.071749  121.058292\n",
      "731  100.000000   98.930059   99.801856  103.868635  107.999841\n",
      "732   99.519325  100.060074  102.533543  104.811736  108.646515\n",
      "\n",
      "[733 rows x 5 columns]\n",
      "change_1d    100.142971\n",
      "change_3d    100.237451\n",
      "change_1w    100.127829\n",
      "change_1m    101.758522\n",
      "change_3m    105.316333\n",
      "dtype: float64\n",
      "768.0\n"
     ]
    }
   ],
   "source": [
    "# What is the baseline performance of the investment bank recommendations?\n",
    "# For Q3 2021:\n",
    "top_banks = ['Morgan Stanley',\n",
    "       'Credit Suisse', 'Wells Fargo', 'Citigroup', 'Barclays',\n",
    "       'Deutsche Bank', 'UBS', 'Raymond James', 'JP Morgan',\n",
    "       'B of A Securities', 'BMO Capital', 'Keybanc', 'RBC Capital',\n",
    "       'Goldman Sachs', 'Mizuho', 'Stifel', 'Piper Sandler', 'Baird',\n",
    "       'Jefferies', 'Oppenheimer']\n",
    "targets = ['change_1d', 'change_3d', 'change_1w', 'change_1m', 'change_3m']\n",
    "\n",
    "top_results_q3 = pd.DataFrame(columns=targets)\n",
    "top_results_q3_count = pd.DataFrame(columns=targets)\n",
    "\n",
    "for df in stock_dfs_filtered:\n",
    "    df = df['2021-07-01':'2021-09-30']   # Filter for Q3 2021\n",
    "    # top_results_q3 = top_results_q3.append(df[targets].loc[df[top_banks].any(1)].mean() + 100, ignore_index=True)\n",
    "    top_results_q3 = top_results_q3.append(df[targets].loc[df[top_banks].any(1)] + 100, ignore_index=True)\n",
    "    top_results_q3_count = top_results_q3_count.append(df[top_banks].loc[df[top_banks].any(1)], ignore_index=True)\n",
    "\n",
    "top_results_q3.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "print(top_results_q3)\n",
    "print(top_results_q3.mean())\n",
    "print(top_results_q3_count.sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "11cb89d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      change_1d   change_3d   change_1w   change_1m   change_3m\n",
      "0    100.000000   99.778691   94.874628   96.022063   91.328669\n",
      "1    104.076718  104.076718  108.028894  101.635671   97.297590\n",
      "2     99.528961   99.271375  101.045108  104.592262  121.532264\n",
      "3     98.263188   99.992650   99.506936  104.511351  123.130717\n",
      "4    100.703683  102.882876  103.578990  111.047208  118.271250\n",
      "..          ...         ...         ...         ...         ...\n",
      "960   99.537345  102.569399  103.833443  110.583282   84.806676\n",
      "961  101.668108  101.668108  101.624594  103.234691   92.355666\n",
      "962  101.083023  102.512031  103.865824  100.737061   91.892294\n",
      "963  102.694855   98.424545   97.733555   95.163074   74.018796\n",
      "964  100.000000   95.167457   98.195442   98.333084   87.322219\n",
      "\n",
      "[965 rows x 5 columns]\n",
      "change_1d    100.122534\n",
      "change_3d    100.208456\n",
      "change_1w    100.325336\n",
      "change_1m     99.736536\n",
      "change_3m     95.476649\n",
      "dtype: float64\n",
      "991.0\n"
     ]
    }
   ],
   "source": [
    "# For Q1 2022:\n",
    "top_results_q1 = pd.DataFrame(columns=targets)\n",
    "top_results_q1_count = pd.DataFrame(columns=targets)\n",
    "\n",
    "for df in stock_dfs_filtered:\n",
    "    df = df['2022-01-01':'2022-03-31']   # Filter \n",
    "    # top_results_q1 = top_results_q1.append(df[targets].loc[df[top_banks].any(1)].mean() + 100, ignore_index=True)\n",
    "    top_results_q1 = top_results_q1.append(df[targets].loc[df[top_banks].any(1)] + 100, ignore_index=True)\n",
    "    top_results_q1_count = top_results_q1_count.append(df[top_banks].loc[df[top_banks].any(1)], ignore_index=True)\n",
    "\n",
    "top_results_q1.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "print(top_results_q1)\n",
    "print(top_results_q1.mean())\n",
    "print(top_results_q1_count.sum().sum())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
